<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Affan Shoukat</title><link>https://affans.github.io/personal/</link><description>Recent content on Affan Shoukat</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 23 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://affans.github.io/personal/index.xml" rel="self" type="application/rss+xml"/><item><title>A Brief Exposition of Lyapunov Functions</title><link>https://affans.github.io/personal/post/lyapunovfunctions/</link><pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate><guid>https://affans.github.io/personal/post/lyapunovfunctions/</guid><description>For a homogeneous dynamical system $$\mathbf{x}^{\prime} = f(\mathbf{x})\quad \text{ or }\quad \frac{dx_i}{dt} = f_i(x_1, x_2, \ldots, x_n) \quad i = 1, 2, \ldots, n$$a point $\mathbf{x_e}$ is an equilibrium point if $\mathbf{f}(\mathbf{x_e}) = 0$.</description></item><item><title>Regularization Techniques in Regression Models</title><link>https://affans.github.io/personal/post/reg-glmnet/</link><pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate><guid>https://affans.github.io/personal/post/reg-glmnet/</guid><description>What is regularization in regression models? Regularization is a modification to a learning algorithm that aims to reduce its generalization error by not its training error.</description></item><item><title>Artificial Neural Networks For Applied Mathematicians</title><link>https://affans.github.io/personal/post/nn-back-prop/</link><pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate><guid>https://affans.github.io/personal/post/nn-back-prop/</guid><description>Consider a neural network with $L$ layers, defined by a mapping $\mathbb{R}^{n_1} \rightarrow \mathbb{R}^{n_L}$ where $n_1$ and $n_L$ are the dimensions of the initial input and final output.</description></item><item><title>Expected Number of Steps in a Random Walk</title><link>https://affans.github.io/personal/post/rd-walk-expectation/</link><pubDate>Sun, 02 May 2021 00:00:00 +0000</pubDate><guid>https://affans.github.io/personal/post/rd-walk-expectation/</guid><description>The follow counter-intuitive result is one of my favourite. The expected number of steps that it takes an unbiased random walk $X_n$ on $\mathbb{Z}$ starting at 0 to get to 1 is infinite.</description></item><item><title>About</title><link>https://affans.github.io/personal/about/</link><pubDate>Sun, 28 Mar 2021 19:43:37 -0400</pubDate><guid>https://affans.github.io/personal/about/</guid><description>Affan Shoukat received his PhD in Applied Mathematics from York University in 2019.</description></item></channel></rss>